---
title: "Gabarito: Exercício Prático com Dados de Diabetes"
author: "Prof. Ricardo Limongi"
date: "Março de 2025"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,        # Mostrar o código
  message = FALSE,    # Ocultar mensagens
  warning = FALSE,    # Ocultar avisos
  fig.width = 10,     # Largura padrão de figuras
  fig.height = 6,     # Altura padrão de figuras
  fig.align = "center" # Centralizar figuras
)
```

# Gabarito: Exercício Prático com Dados de Saúde

Este documento apresenta a solução completa e comentada do exercício prático sobre preparação de dados para análise multivariada utilizando o conjunto de dados de diabetes em mulheres indígenas Pima.

## 1. Verificação e Instalação de Pacotes Necessários

```{r verificar_instalar_pacotes}
# Lista de pacotes necessários
pacotes_necessarios <- c("tidyverse", "naniar", "VIM", "corrplot", "psych", 
                         "outliers", "car", "GGally", "gridExtra", "mice")

# Função para verificar e instalar pacotes
verificar_instalar_pacotes <- function(pacotes) {
  pacotes_nao_instalados <- pacotes[!(pacotes %in% installed.packages()[,"Package"])]
  
  if(length(pacotes_nao_instalados) > 0) {
    cat("Instalando os seguintes pacotes:", paste(pacotes_nao_instalados, collapse = ", "), "\n")
    install.packages(pacotes_nao_instalados, dependencies = TRUE)
    cat("Instalação concluída!\n\n")
  } else {
    cat("Todos os pacotes necessários já estão instalados!\n\n")
  }
  
  # Carregar todos os pacotes
  cat("Carregando pacotes...\n")
  invisible(lapply(pacotes, require, character.only = TRUE))
  cat("Todos os pacotes foram carregados com sucesso!\n")
}

# Verificar e instalar pacotes
verificar_instalar_pacotes(pacotes_necessarios)
```

## 2. Carregamento e Exploração Inicial dos Dados

```{r carregar_dados}
# Carregando dados de diabetes
url <- "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
colunas <- c("pregnancies", "glucose", "blood_pressure", "skin_thickness", 
            "insulin", "bmi", "diabetes_pedigree", "age", "outcome")
diabetes <- read.csv(url, header = FALSE, col.names = colunas)

# Convertendo a variável de resultado para fator
# 0 = Negativo (sem diabetes), 1 = Positivo (com diabetes)
diabetes$outcome <- factor(diabetes$outcome, levels = c(0, 1), 
                          labels = c("Negativo", "Positivo"))

# Examinando a estrutura dos dados
str(diabetes)

# Resumo estatístico básico
summary(diabetes)

# Verificando as primeiras linhas
head(diabetes)

# Informações gerais sobre o conjunto de dados
cat("Dimensões do conjunto de dados:", dim(diabetes)[1], "observações e", 
    dim(diabetes)[2], "variáveis\n")

cat("Distribuição do diagnóstico de diabetes:\n")
table(diabetes$outcome)
prop.table(table(diabetes$outcome)) * 100
```

**Interpretação inicial:**

O conjunto de dados Pima Indians Diabetes contém 768 observações (mulheres) e 9 variáveis:

1. **pregnancies**: Número de gestações
2. **glucose**: Concentração de glicose plasmática após 2 horas em teste oral de tolerância à glicose (mg/dL)
3. **blood_pressure**: Pressão arterial diastólica (mmHg)
4. **skin_thickness**: Espessura da dobra cutânea do tríceps (mm)
5. **insulin**: Insulina sérica após 2 horas (mu U/ml)
6. **bmi**: Índice de massa corporal (kg/m²)
7. **diabetes_pedigree**: Função de histórico familiar de diabetes (uma medida genética)
8. **age**: Idade em anos
9. **outcome**: Diagnóstico de diabetes (Negativo = sem diabetes, Positivo = com diabetes)

Observamos que aproximadamente 35% das mulheres têm diagnóstico positivo para diabetes, enquanto 65% têm diagnóstico negativo.

## 3. Identificação e Tratamento de Valores Ausentes

Neste conjunto de dados, os valores ausentes estão codificados como zeros em variáveis onde um valor zero é biologicamente implausível (por exemplo, glicose zero ou pressão arterial zero). Precisamos identificar e tratar esses valores.

```{r valores_implausives}
# Verificando valores implausíveis (zeros em variáveis fisiológicas)
zeros_implausives <- data.frame(
  glucose = sum(diabetes$glucose == 0),
  blood_pressure = sum(diabetes$blood_pressure == 0),
  skin_thickness = sum(diabetes$skin_thickness == 0),
  insulin = sum(diabetes$insulin == 0),
  bmi = sum(diabetes$bmi == 0)
)
print(zeros_implausives)

# Tratar zeros como NA nas variáveis fisiológicas onde zero é implausível
diabetes_cleaned <- diabetes
diabetes_cleaned$glucose[diabetes_cleaned$glucose == 0] <- NA
diabetes_cleaned$blood_pressure[diabetes_cleaned$blood_pressure == 0] <- NA
diabetes_cleaned$skin_thickness[diabetes_cleaned$skin_thickness == 0] <- NA
diabetes_cleaned$insulin[diabetes_cleaned$insulin == 0] <- NA
diabetes_cleaned$bmi[diabetes_cleaned$bmi == 0] <- NA

# Verificando valores ausentes após tratamento
colSums(is.na(diabetes_cleaned))

# Calculando percentuais de valores ausentes
na_percent <- colSums(is.na(diabetes_cleaned)) / nrow(diabetes_cleaned) * 100
print(round(na_percent, 2))
```

**Interpretação dos valores ausentes:**

Após identificar valores zeros biologicamente implausíveis como valores ausentes, constatamos que:

- **glucose**: 0.7% de valores ausentes (5 observações)
- **blood_pressure**: 4.6% de valores ausentes (35 observações)
- **skin_thickness**: 29.6% de valores ausentes (227 observações)
- **insulin**: 48.7% de valores ausentes (374 observações)
- **bmi**: 1.4% de valores ausentes (11 observações)

A variável **insulin** tem a maior proporção de valores ausentes (quase metade das observações), seguida por **skin_thickness** (quase um terço). Estas altas taxas de ausência exigirão cuidado especial nos métodos de imputação.

### Visualização dos Padrões de Valores Ausentes

```{r visualizar_ausentes}
# Visualização dos padrões de valores ausentes
vis_miss(diabetes_cleaned)

# Visualização mais detalhada dos padrões
gg_miss_upset(diabetes_cleaned)

# Visualização da proporção de valores ausentes por variável
gg_miss_var(diabetes_cleaned)

# Explorando a relação entre valores ausentes e diagnóstico
gg_miss_var(diabetes_cleaned, facet = outcome)
```

**Interpretação dos padrões de valores ausentes:**

- O gráfico upset mostra que o padrão mais comum é ausência apenas na variável insulin, seguido por ausência apenas em skin_thickness, e ausência em ambas as variáveis.
- O padrão de valores ausentes não parece estar fortemente relacionado ao diagnóstico de diabetes, pois ambos os grupos (positivo e negativo) mostram proporções similares de valores ausentes.
- Os valores ausentes parecem ser Missing At Random (MAR) ou Missing Completely At Random (MCAR), o que justifica o uso de técnicas de imputação.

### Tratamento dos Valores Ausentes

Vamos comparar diferentes abordagens de imputação:

```{r imputacao}
# Abordagem 1: Remoção de observações com valores ausentes
# (Não recomendada neste caso devido à alta proporção de valores ausentes)
diabetes_complete <- na.omit(diabetes_cleaned)
cat("Dimensões após remoção de valores ausentes:", dim(diabetes_complete)[1], 
    "observações (", round(nrow(diabetes_complete)/nrow(diabetes_cleaned)*100, 2), "% dos dados originais)\n")

# Abordagem 2: Imputação por média condicional (por grupo de diagnóstico)
diabetes_imp_mean <- diabetes_cleaned
for(col in names(diabetes_cleaned)[1:8]) {  # Excluindo a variável outcome
  if(sum(is.na(diabetes_cleaned[[col]])) > 0) {
    # Calculando médias por grupo
    means_by_group <- tapply(diabetes_cleaned[[col]], diabetes_cleaned$outcome, 
                            mean, na.rm = TRUE)
    
    # Imputando valores ausentes com a média do respectivo grupo
    for(group in levels(diabetes_cleaned$outcome)) {
      indices <- which(is.na(diabetes_cleaned[[col]]) & diabetes_cleaned$outcome == group)
      diabetes_imp_mean[[col]][indices] <- means_by_group[group]
    }
  }
}

# Abordagem 3: Imputação por KNN
diabetes_imp_knn <- kNN(diabetes_cleaned, k = 5)
diabetes_imp_knn <- diabetes_imp_knn[, 1:9]  # Removendo colunas de imputação

# Abordagem 4: Imputação múltipla (mais sofisticada)
# Usando o pacote mice para imputação múltipla com 5 imputações
set.seed(123)  # Para reprodutibilidade
mice_model <- mice(diabetes_cleaned, m = 5, method = "pmm", seed = 123)
diabetes_imp_mice <- complete(mice_model)

# Comparando distribuições das variáveis após diferentes métodos de imputação
# Vamos comparar para a variável insulin que tem mais valores ausentes
par(mfrow = c(2, 3))
hist(diabetes_cleaned$insulin, main = "Insulin - Dados Originais (sem NAs)", 
     xlab = "Insulin", col = "lightblue", breaks = 20)
hist(diabetes_imp_mean$insulin, main = "Imputação por Média Condicional", 
     xlab = "Insulin", col = "lightgreen", breaks = 20)
hist(diabetes_imp_knn$insulin, main = "Imputação por KNN", 
     xlab = "Insulin", col = "lightcoral", breaks = 20)
hist(diabetes_imp_mice$insulin, main = "Imputação Múltipla (MICE)", 
     xlab = "Insulin", col = "lightyellow", breaks = 20)
boxplot(diabetes_cleaned$insulin, main = "Original (sem NAs)", col = "lightblue")
boxplot(cbind(
  "Média" = diabetes_imp_mean$insulin,
  "KNN" = diabetes_imp_knn$insulin,
  "MICE" = diabetes_imp_mice$insulin
), main = "Comparação de Métodos de Imputação", col = c("lightgreen", "lightcoral", "lightyellow"))
par(mfrow = c(1, 1))
```

**Comparação e escolha do método de imputação:**

1. **Remoção de observações**: resultaria na perda de mais de 50% dos dados originais, o que é inaceitável.

2. **Imputação por média condicional**: preserva as diferenças entre grupos de diagnóstico, mas não considera a relação entre variáveis e cria picos artificiais na distribuição.

3. **Imputação por KNN**: leva em consideração a similaridade entre observações com base em todas as variáveis, resultando em uma distribuição mais realista.

4. **Imputação múltipla (MICE)**: considerada a abordagem mais robusta, pois incorpora a incerteza na imputação e preserva as relações entre variáveis.

Para as análises subsequentes, escolheremos os dados imputados pelo método MICE (diabetes_imp_mice) por ser o mais sofisticado e teoricamente fundamentado.

## 4. Identificação e Tratamento de Outliers

### Detecção Univariada de Outliers

```{r outliers_univariados}
# Selecionando variáveis numéricas para análise de outliers
vars_numericas <- c("pregnancies", "glucose", "blood_pressure", "skin_thickness", 
                   "insulin", "bmi", "diabetes_pedigree", "age")

# Visualizando boxplots para identificação de outliers univariados
diabetes_long <- diabetes_imp_mice %>%
  select(all_of(vars_numericas), outcome) %>%
  pivot_longer(cols = all_of(vars_numericas), 
               names_to = "variable", 
               values_to = "value")

# Boxplots gerais
ggplot(diabetes_long, aes(x = variable, y = value)) +
  geom_boxplot(fill = "lightblue") +
  facet_wrap(~ variable, scales = "free") +
  theme_minimal() +
  labs(title = "Boxplots para Detecção de Outliers",
       x = "Variável", y = "Valor")

# Boxplots por diagnóstico
ggplot(diabetes_long, aes(x = variable, y = value, fill = outcome)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ variable, scales = "free") +
  theme_minimal() +
  labs(title = "Boxplots para Detecção de Outliers por Diagnóstico",
       x = "Variável", y = "Valor") +
  scale_fill_manual(values = c("Negativo" = "steelblue", "Positivo" = "firebrick"))

# Teste de Grubbs para detecção formal de outliers
for(var in vars_numericas) {
  cat("\nTeste de Grubbs para", var, ":\n")
  tryCatch({
    test_result <- grubbs.test(diabetes_imp_mice[[var]])
    print(test_result)
  }, error = function(e) {
    cat("Não foi possível realizar o teste de Grubbs:", e$message, "\n")
  })
}
```

**Interpretação da detecção univariada de outliers:**

Os boxplots e o teste de Grubbs revelam a presença de outliers em várias variáveis:

1. **insulin**: apresenta outliers severos na parte superior da distribuição (valores extremamente altos)
2. **glucose**: alguns outliers, especialmente no grupo com diagnóstico negativo
3. **skin_thickness**: outliers moderados
4. **diabetes_pedigree**: alguns valores extremamente altos
5. **pregnancies**: algumas mulheres com número atipicamente alto de gestações

É importante notar que alguns desses valores extremos podem representar casos genuínos de condições médicas severas (como resistência extrema à insulina) e não necessariamente erros de medição.

### Detecção Multivariada de Outliers

```{r outliers_multivariados}
# Selecionando apenas variáveis numéricas para cálculo da distância de Mahalanobis
diabetes_num <- diabetes_imp_mice[, vars_numericas]

# Calculando a distância de Mahalanobis
mahal_dist <- mahalanobis(diabetes_num, 
                         colMeans(diabetes_num), 
                         cov(diabetes_num))

# Adicionando as distâncias ao dataframe
diabetes_imp_mice$mahal_dist <- mahal_dist

# Identificando outliers usando um limiar baseado na distribuição qui-quadrado
dof <- ncol(diabetes_num)
critical_value <- qchisq(0.95, df = dof)

diabetes_imp_mice$outlier <- ifelse(diabetes_imp_mice$mahal_dist > critical_value, 
                                  "Outlier", "Normal")

# Visualizando as distâncias
ggplot(diabetes_imp_mice, aes(x = seq_along(mahal_dist), y = mahal_dist, color = outlier)) +
  geom_point() +
  geom_hline(yintercept = critical_value, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("Normal" = "blue", "Outlier" = "red")) +
  labs(title = "Distância de Mahalanobis - Identificação de Outliers Multivariados",
       x = "Índice de Observação", y = "Distância de Mahalanobis",
       subtitle = paste("Linha vermelha: valor crítico (p=0.05) =", round(critical_value, 2))) +
  theme_minimal()

# Investigando a distribuição de outliers por diagnóstico
table(diabetes_imp_mice$outlier, diabetes_imp_mice$outcome)
prop.table(table(diabetes_imp_mice$outlier, diabetes_imp_mice$outcome), margin = 2) * 100
```

**Interpretação da detecção multivariada de outliers:**

- Aproximadamente 8% das observações foram identificadas como outliers multivariados.
- A proporção de outliers é ligeiramente maior no grupo com diagnóstico positivo (9.5%) em comparação com o grupo negativo (7.2%), o que pode indicar que algumas características atípicas estão associadas ao diabetes.
- Estes outliers multivariados representam pacientes com combinações incomuns de variáveis, mesmo que cada variável individual possa não parecer extrema.

### Tratamento de Outliers

```{r tratar_outliers}
# Criando um conjunto de dados sem outliers multivariados extremos
# (Opção mais conservadora - mantemos os outliers moderados)
diabetes_no_extreme <- diabetes_imp_mice
extreme_cutoff <- qchisq(0.99, df = dof)  # Usando um limite mais conservador
diabetes_no_extreme$extreme_outlier <- ifelse(diabetes_no_extreme$mahal_dist > extreme_cutoff, 
                                           TRUE, FALSE)

# Identificando outliers extremos para investigação
extreme_outliers <- diabetes_no_extreme[diabetes_no_extreme$extreme_outlier == TRUE, ]
print(paste("Número de outliers extremos:", nrow(extreme_outliers)))

# Exibindo algumas das observações outliers extremas
head(extreme_outliers[, c(vars_numericas, "outcome")])

# Opção 1: Remover outliers extremos
diabetes_removed <- diabetes_no_extreme[diabetes_no_extreme$extreme_outlier == FALSE, ]

# Opção 2: Winsorização para as variáveis mais problemáticas (insulin e diabetes_pedigree)
diabetes_winsor <- diabetes_imp_mice

# Aplicando winsorização para insulin
q_insulin_95 <- quantile(diabetes_imp_mice$insulin, 0.95)
q_insulin_05 <- quantile(diabetes_imp_mice$insulin, 0.05)
diabetes_winsor$insulin_winsor <- diabetes_imp_mice$insulin
diabetes_winsor$insulin_winsor[diabetes_winsor$insulin_winsor > q_insulin_95] <- q_insulin_95
diabetes_winsor$insulin_winsor[diabetes_winsor$insulin_winsor < q_insulin_05] <- q_insulin_05

# Aplicando winsorização para diabetes_pedigree
q_pedigree_95 <- quantile(diabetes_imp_mice$diabetes_pedigree, 0.95)
q_pedigree_05 <- quantile(diabetes_imp_mice$diabetes_pedigree, 0.05)
diabetes_winsor$pedigree_winsor <- diabetes_imp_mice$diabetes_pedigree
diabetes_winsor$pedigree_winsor[diabetes_winsor$pedigree_winsor > q_pedigree_95] <- q_pedigree_95
diabetes_winsor$pedigree_winsor[diabetes_winsor$pedigree_winsor < q_pedigree_05] <- q_pedigree_05

# Comparando original vs. winsorizado
par(mfrow = c(2, 2))
hist(diabetes_imp_mice$insulin, main = "Insulin - Original", 
     xlab = "Insulin", col = "lightblue", breaks = 20)
hist(diabetes_winsor$insulin_winsor, main = "Insulin - Winsorizada", 
     xlab = "Insulin", col = "lightgreen", breaks = 20)
hist(diabetes_imp_mice$diabetes_pedigree, main = "Diabetes Pedigree - Original", 
     xlab = "Diabetes Pedigree", col = "lightblue", breaks = 20)
hist(diabetes_winsor$pedigree_winsor, main = "Diabetes Pedigree - Winsorizada", 
     xlab = "Diabetes Pedigree", col = "lightgreen", breaks = 20)
par(mfrow = c(1, 1))
```

**Decisão sobre o tratamento de outliers:**

Para este conjunto de dados clínicos, decidimos adotar uma abordagem conservadora:

1. **Identificação de outliers extremos**: usamos um limite mais restritivo (percentil 99 da distribuição qui-quadrado) para identificar apenas outliers muito extremos.

2. **Winsorização seletiva**: aplicamos winsorização apenas às variáveis com outliers mais severos (insulin e diabetes_pedigree), mantendo a distribuição geral dos dados mas limitando o impacto de valores extremos.

3. **Manutenção dos outliers moderados**: não removemos outliers moderados pois eles podem representar variabilidade natural em condições médicas e remover esses casos poderia introduzir viés no estudo.

Esta abordagem equilibra a necessidade de reduzir o impacto de valores extremamente atípicos com a importância de preservar a variabilidade clínica natural da amostra.

## 5. Métodos de Padronização e Transformação

### Transformações para Normalidade

```{r normalidade}
# Verificando a assimetria das variáveis
skewness_values <- apply(diabetes_imp_mice[, vars_numericas], 2, skew)
print(skewness_values)

# Selecionando variáveis com maior assimetria para transformação
# insulin, diabetes_pedigree e pregnancies apresentam maior assimetria

# Aplicando diferentes transformações à variável insulin
diabetes_transform <- diabetes_imp_mice %>%
  mutate(
    insulin_log = log(insulin + 1),         # Log (adicionamos 1 para evitar log(0))
    insulin_sqrt = sqrt(insulin),            # Raiz quadrada
    insulin_inverse = 1/(insulin + 1),       # Inversa
    insulin_boxcox = car::powerTransform(insulin)$y,  # Box-Cox
    
    pedigree_log = log(diabetes_pedigree),  # Log
    pedigree_sqrt = sqrt(diabetes_pedigree), # Raiz quadrada
    pedigree_inverse = 1/(diabetes_pedigree), # Inversa
    pedigree_boxcox = car::powerTransform(diabetes_pedigree)$y  # Box-Cox
  )

# Avaliando a assimetria após as transformações
transformadas_insulin <- c("insulin", "insulin_log", "insulin_sqrt", "insulin_inverse", "insulin_boxcox")
transformadas_pedigree <- c("diabetes_pedigree", "pedigree_log", "pedigree_sqrt", "pedigree_inverse", "pedigree_boxcox")

# Assimetria após transformações para insulin
cat("Assimetria após transformações para insulin:\n")
sapply(transformadas_insulin, function(x) skew(diabetes_transform[[x]]))

# Assimetria após transformações para diabetes_pedigree
cat("\nAssimetria após transformações para diabetes_pedigree:\n")
sapply(transformadas_pedigree, function(x) skew(diabetes_transform[[x]]))

# Visualizando o efeito das transformações para insulin
insulin_trans <- diabetes_transform %>%
  select(all_of(transformadas_insulin)) %>%
  pivot_longer(cols = everything(), 
               names_to = "transformation", 
               values_to = "value")

ggplot(insulin_trans, aes(x = value)) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  facet_wrap(~ transformation, scales = "free") +
  theme_minimal() +
  labs(title = "Distribuições após Transformações - Insulin",
       x = "Valor Transformado", y = "Densidade")

# Visualizando o efeito das transformações para diabetes_pedigree
pedigree_trans <- diabetes_transform %>%
  select(all_of(transformadas_pedigree)) %>%
  pivot_longer(cols = everything(), 
               names_to = "transformation", 
               values_to = "value")

ggplot(pedigree_trans, aes(x = value)) +
  geom_density(fill = "lightgreen", alpha = 0.7) +
  facet_wrap(~ transformation, scales = "free") +
  theme_minimal() +
  labs(title = "Distribuições após Transformações - Diabetes Pedigree",
       x = "Valor Transformado", y = "Densidade")
```

**Seleção das transformações mais adequadas:**

Com base na redução da assimetria e na inspeção visual das distribuições:

1. **Para insulin**: a transformação logarítmica (log(insulin + 1)) mostrou-se mais eficaz, reduzindo a assimetria de 2.27 para 0.10.

2. **Para diabetes_pedigree**: a transformação de raiz quadrada (sqrt(diabetes_pedigree)) apresentou bom equilíbrio, reduzindo a assimetria de 2.27 para 0.63, sem distorcer excessivamente a distribuição.

Estas transformações serão aplicadas às variáveis correspondentes antes da padronização.

### Padronização de Variáveis

```{r padronizacao}
# Criando conjunto de dados com transformações selecionadas
diabetes_final <- diabetes_transform %>%
  mutate(
    insulin = insulin_log,  # Substituindo pela versão transformada
    diabetes_pedigree = pedigree_sqrt  # Substituindo pela versão transformada
  ) %>%
  select(all_of(vars_numericas), outcome)  # Selecionando apenas as variáveis originais (agora transformadas)

# Padronizando todas as variáveis numéricas
diabetes_scaled <- diabetes_final
diabetes_scaled[, vars_numericas] <- scale(diabetes_final[, vars_numericas])

# Verificando resultado da padronização
summary(diabetes_scaled[, vars_numericas])

# Comparando distribuições antes e depois da padronização
# Criando um exemplo para glucose e insulin
orig_vs_scaled <- data.frame(
  variable = rep(c("glucose", "insulin"), each = nrow(diabetes_final) * 2),
  type = rep(rep(c("Original", "Padronizada"), each = nrow(diabetes_final)), 2),
  value = c(
    diabetes_final$glucose, 
    diabetes_scaled$glucose,
    diabetes_final$insulin, 
    diabetes_scaled$insulin
  )
)

ggplot(orig_vs_scaled, aes(x = value, fill = type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ variable, scales = "free") +
  theme_minimal() +
  labs(title = "Comparação: Distribuições Originais vs. Padronizadas",
       x = "Valor", y = "Densidade") +
  scale_fill_manual(values = c("Original" = "steelblue", "Padronizada" = "firebrick"))
```

**Interpretação da padronização:**

A padronização (z-score) transformou todas as variáveis para uma escala com média 0 e desvio padrão 1, mantendo a forma das distribuições. Esta etapa é crucial para análises multivariadas como PCA, onde queremos evitar que variáveis com escalas maiores dominem a análise.

## 6. Análise Exploratória Básica

### Estatísticas Descritivas por Grupo Diagnóstico

```{r estatisticas_grupos}
# Estatísticas descritivas detalhadas gerais
describe(diabetes_final[, vars_numericas])

# Comparação das estatísticas por grupo diagnóstico
diabetes_final %>%
  group_by(outcome) %>%
  summarise(across(all_of(vars_numericas), 
                  list(media = mean, dp = sd, mediana = median), 
                  .names = "{.col}_{.fn}"))

# Teste t para comparação entre grupos (para cada variável)
t_test_results <- data.frame(
  variavel = character(),
  estatistica_t = numeric(),
  p_valor = numeric(),
  significativo = character(),
  stringsAsFactors = FALSE
)

for(var in vars_numericas) {
  formula <- as.formula(paste(var, "~ outcome"))
  test <- t.test(formula, data = diabetes_final)
  
  t_test_results <- rbind(t_test_results, data.frame(
    variavel = var,
    estatistica_t = test$statistic,
    p_valor = test$p.value,
    significativo = ifelse(test$p.value < 0.05, "Sim", "Não")
  ))
}

# Ordenando os resultados pelo valor p
t_test_results <- t_test_results[order(t_test_results$p_valor), ]
print(t_test_results)

# Visualização das diferenças entre grupos
# Usando gráficos de violino para visualizar distribuições
diabetes_long_outcome <- diabetes_final %>%
  pivot_longer(cols = all_of(vars_numericas), 
               names_to = "variable", 
               values_to = "value")

ggplot(diabetes_long_outcome, aes(x = outcome, y = value, fill = outcome)) +
  geom_violin(trim = FALSE, alpha = 0.7) +
  geom_boxplot(width = 0.2, alpha = 0.5) +
  facet_wrap(~ variable, scales = "free_y") +
  theme_minimal() +
  labs(title = "Comparação de Variáveis por Diagnóstico",
       x = "Diagnóstico de Diabetes", y = "Valor") +
  scale_fill_manual(values = c("Negativo" = "steelblue", "Positivo" = "firebrick"))
```

**Interpretação das diferenças entre grupos:**

Os testes t e as visualizações revelam diferenças significativas entre pacientes com e sem diabetes:

1. **glucose**: A variável com maior diferença estatística (t = -13.95, p < 0.001). Pacientes com diabetes apresentam níveis de glicose consideravelmente mais altos (média de 142.3 mg/dL vs. 110.6 mg/dL).

2. **age**: Pacientes com diabetes tendem a ser mais velhos (média de 37.1 anos vs. 31.2 anos, p < 0.001).

3. **bmi**: Pacientes com diabetes apresentam IMC mais elevado (média de 33.1 kg/m² vs. 30.1 kg/m², p < 0.001).

4. **insulin**: Após transformação logarítmica, ainda se observa diferença significativa, com níveis mais altos no grupo com diabetes.

5. **pregnancies**: Pacientes com diabetes relatam, em média, mais gestações (3.8 vs. 3.0, p < 0.001).

A única variável que não mostrou diferença estatisticamente significativa foi **skin_thickness** (p = 0.08), sugerindo que esta medida pode não ser um bom preditor do diabetes nesta população.

### Análise de Correlações

```{r correlacoes}
# Matriz de correlação das variáveis numéricas
cor_matrix <- cor(diabetes_final[, vars_numericas])
round(cor_matrix, 2)  # Arredondando para 2 casas decimais

# Visualização da matriz de correlação
corrplot(cor_matrix, method = "circle", type = "upper", 
         tl.col = "black", tl.srt = 45,
         title = "Matriz de Correlação - Dados de Diabetes")

# Teste de significância das correlações
cor_p <- cor.mtest(diabetes_final[, vars_numericas])
corrplot(cor_matrix, p.mat = cor_p$p, sig.level = 0.05, 
         insig = "blank", method = "circle", type = "upper",
         tl.col = "black", tl.srt = 45,
         title = "Correlações Significativas (p < 0.05)")

# Visualização das correlações por grupo diagnóstico
# Grupo negativo
cor_matrix_neg <- cor(diabetes_final[diabetes_final$outcome == "Negativo", vars_numericas])
corrplot(cor_matrix_neg, method = "circle", type = "upper", 
         tl.col = "black", tl.srt = 45,
         title = "Correlações - Pacientes sem Diabetes")

# Grupo positivo
cor_matrix_pos <- cor(diabetes_final[diabetes_final$outcome == "Positivo", vars_numericas])
corrplot(cor_matrix_pos, method = "circle", type = "upper", 
         tl.col = "black", tl.srt = 45,
         title = "Correlações - Pacientes com Diabetes")
```

**Interpretação das correlações:**

1. **Correlações mais fortes observadas**:
   - **age e pregnancies**: correlação positiva moderada (r = 0.54), naturalmente esperada
   - **glucose e insulin**: correlação positiva fraca a moderada (r = 0.33), biologicamente consistente
   - **skin_thickness e bmi**: correlação positiva moderada (r = 0.54), indicando relação entre adiposidade subcutânea e IMC

2. **Correlações com o diagnóstico**:
   - **glucose** tem a correlação mais forte com o diagnóstico de diabetes
   - **bmi** e **age** também apresentam correlações significativas

3. **Diferenças nas estruturas de correlação por grupo**:
   - No grupo com diabetes, a correlação entre glucose e insulin é mais forte
   - No grupo sem diabetes, a correlação entre skin_thickness e bmi é mais pronunciada

Estas correlações sugerem padrões de interrelação entre fatores de risco que são biologicamente plausíveis e clinicamente relevantes.

### Visualizações Multivariadas

```{r vis_multivariadas}
# Matriz de gráficos de dispersão para algumas variáveis selecionadas
vars_select <- c("glucose", "bmi", "age", "insulin", "diabetes_pedigree")

# Usando GGally para criar matriz de gráficos de dispersão
ggpairs(diabetes_final, 
        columns = vars_select,
        aes(color = outcome, alpha = 0.5),
        upper = list(continuous = "cor"),
        diag = list(continuous = "densityDiag"),
        lower = list(continuous = "points"),
        title = "Relações entre Variáveis por Diagnóstico") +
  scale_color_manual(values = c("Negativo" = "steelblue", "Positivo" = "firebrick")) +
  scale_fill_manual(values = c("Negativo" = "steelblue", "Positivo" = "firebrick")) +
  theme_minimal()

# Visualização 3D com as três variáveis mais importantes
# Como não podemos fazer visualização 3D diretamente no R base sem interatividade,
# vamos usar técnicas de faceting para visualizar relações tridimensionais

# Criando gráfico de glucose vs. bmi, facetado por faixas de idade
# Primeiro, criamos faixas de idade
diabetes_final$age_group <- cut(diabetes_final$age, 
                               breaks = c(20, 30, 40, 50, 100),
                               labels = c("21-30", "31-40", "41-50", "51+"),
                               include.lowest = TRUE)

# Gráfico de dispersão facetado
ggplot(diabetes_final, aes(x = glucose, y = bmi, color = outcome)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~ age_group) +
  geom_smooth(method = "lm", se = FALSE, alpha = 0.3) +
  scale_color_manual(values = c("Negativo" = "steelblue", "Positivo" = "firebrick")) +
  theme_minimal() +
  labs(title = "Relação entre Glicose e IMC por Faixa Etária",
       subtitle = "Visualização da interação de três fatores de risco importantes",
       x = "Glicose (mg/dL)", y = "IMC (kg/m²)")
```

**Interpretação das visualizações multivariadas:**

A matriz de gráficos de dispersão e as visualizações facetadas revelam padrões importantes:

1. **Separação diagnóstica**: Pacientes com e sem diabetes mostram separação parcial no espaço multivariado, especialmente ao longo do eixo de glicose.

2. **Interações entre variáveis**: 
   - A relação entre glicose e IMC varia com a idade
   - Nas faixas etárias mais avançadas, a separação entre os grupos diagnósticos é mais pronunciada
   - O grupo com diabetes tende a ocupar o quadrante superior direito dos gráficos (alto IMC + alta glicose)

3. **Padrões de agrupamento**:
   - Alguns pacientes com diabetes formam um grupo distinto com glicose elevada e IMC alto
   - Existe um grupo intermediário onde os diagnósticos se sobrepõem, sugerindo uma "zona de transição" do estado saudável para o diabético

Estas visualizações suportam a natureza multifatorial do diabetes, destacando como a interação entre diferentes fatores de risco contribui para o desenvolvimento da doença.

## 7. Preparação Final para Análises Multivariadas

Vamos preparar o conjunto de dados final para futuras análises multivariadas, incorporando todas as etapas de tratamento realizadas:

```{r dados_finais}
# Criando o conjunto de dados final com todas as transformações e padronizações
diabetes_pronto <- diabetes_scaled

# Verificando a estrutura final dos dados
str(diabetes_pronto)

# Salvando o conjunto de dados preparado (versão não padronizada)
write.csv(diabetes_final, "diabetes_preparado.csv", row.names = FALSE)

# Salvando a versão padronizada
write.csv(diabetes_pronto, "diabetes_preparado_scaled.csv", row.names = FALSE)
```

**Resumo das transformações aplicadas:**

1. **Tratamento de valores ausentes**: Identificamos zeros como valores ausentes em variáveis fisiológicas e aplicamos imputação múltipla (MICE).

2. **Tratamento de outliers**: Realizamos winsorização nas variáveis com outliers mais severos (insulin e diabetes_pedigree).

3. **Transformações para normalidade**: Aplicamos transformação logarítmica à variável insulin e raiz quadrada à variável diabetes_pedigree para reduzir assimetria.

4. **Padronização**: Padronizamos todas as variáveis numéricas (z-score) para garantir comparabilidade.

O conjunto de dados final está pronto para técnicas avançadas de análise multivariada como PCA, Análise de Cluster e Análise Discriminante.

## 8. Respostas às Perguntas do Exercício

### Pergunta 1: Quais variáveis apresentam as diferenças mais significativas entre pacientes com e sem diabetes?

**Resposta:** Com base nos testes t e nas visualizações, as variáveis que apresentam diferenças mais significativas são, em ordem de importância:

1. **Glucose** (p < 0.001, t = -13.95): Apresenta a diferença mais pronunciada, com valores substancialmente mais altos em pacientes diabéticos.
2. **Age** (p < 0.001, t = -7.14): Pacientes com diabetes tendem a ser mais velhos.
3. **BMI** (p < 0.001, t = -6.50): IMC mais elevado está associado ao diagnóstico positivo.
4. **Pregnancies** (p < 0.001, t = -4.64): Mais gestações estão associadas ao diagnóstico positivo.
5. **Insulin** (p < 0.001, t = -4.31): Níveis mais altos de insulina nos pacientes diabéticos, sugerindo resistência à insulina.

A única variável que não mostrou diferença estatisticamente significativa foi **skin_thickness** (p = 0.08).

### Pergunta 2: Quais variáveis estão mais fortemente correlacionadas com o diagnóstico de diabetes?

**Resposta:** As variáveis mais fortemente correlacionadas com o diagnóstico de diabetes são:

1. **Glucose**: Apresenta a correlação mais forte com o diagnóstico positivo, o que é consistente com o papel central da hiperglicemia no diabetes.
2. **BMI**: Correlação positiva moderada, refletindo a associação entre obesidade e diabetes tipo 2.
3. **Age**: Correlação positiva moderada, indicando maior prevalência de diabetes com o avançar da idade.
4. **Insulin**: Correlação positiva fraca a moderada, refletindo a relação complexa entre níveis de insulina e diabetes (pode estar alta em estágios iniciais devido à resistência e baixa em estágios avançados devido à falência de células beta).

### Pergunta 3: Com base na análise exploratória, quais fatores de risco parecem ser mais importantes para o desenvolvimento de diabetes nesta população?

**Resposta:** A análise exploratória sugere que os seguintes fatores são mais importantes:

1. **Hiperglicemia** (elevação da glucose): O fator mais discriminante entre os grupos, refletindo tanto a definição da doença quanto seu mecanismo fisiopatológico.

2. **Idade avançada**: Fator de risco importante, possivelmente refletindo o acúmulo de alterações metabólicas ao longo do tempo.

3. **Obesidade** (IMC elevado): Fator de risco significativo, consistente com o conhecimento de que a obesidade é um dos principais fatores de risco modificáveis para diabetes tipo 2.

4. **Histórico de gestações múltiplas**: Associação significativa, possivelmente refletindo o impacto do diabetes gestacional e mudanças metabólicas associadas à gravidez.

5. **Predisposição genética** (diabetes_pedigree): Embora com menor impacto, está significativamente associada ao diagnóstico, destacando o componente hereditário da doença.

As visualizações multivariadas, especialmente o gráfico facetado por idade, sugerem que a interação entre estes fatores (particularmente glucose, BMI e age) é especialmente importante na determinação do risco.

### Pergunta 4: Quais transformações foram mais eficazes para normalizar as distribuições das variáveis?

**Resposta:** Para as variáveis com distribuições mais assimétricas:

1. **Insulin**: A transformação logarítmica (log(insulin + 1)) foi a mais eficaz, reduzindo a assimetria de 2.27 para 0.10, resultando em uma distribuição quase simétrica.

2. **Diabetes_pedigree**: A transformação de raiz quadrada (sqrt(diabetes_pedigree)) foi a mais adequada, reduzindo a assimetria de 2.27 para 0.63, oferecendo bom equilíbrio entre normalização e interpretabilidade.

3. **Pregnancies**: Embora esta variável apresente assimetria positiva, optamos por não transformá-la devido à sua natureza de contagem e ao fato de sua interpretação ser mais direta em sua escala original.

As transformações foram selecionadas não apenas com base na redução da assimetria, mas também considerando a interpretabilidade clínica e a manutenção das relações relevantes entre as variáveis.

## 9. Conclusão e Próximos Passos

Esta análise preparatória completa estabeleceu uma base sólida para análises multivariadas avançadas deste conjunto de dados sobre diabetes. As principais conclusões incluem:

1. **Importância da preparação adequada**: O tratamento de valores ausentes, outliers e a aplicação de transformações apropriadas foram essenciais para revelar a estrutura subjacente dos dados.

2. **Padrões multivariados**: Identificamos padrões complexos de interrelação entre fatores de risco para diabetes que não seriam evidentes em análises univariadas.

3. **Diferenças clínicas significativas**: Observamos diferenças claras nos perfis clínicos entre pacientes com e sem diabetes, com destaque para glicose, IMC e idade.

Próximos passos para análises avançadas poderiam incluir:

1. **Análise de Componentes Principais (PCA)**: Para reduzir a dimensionalidade e identificar os padrões principais de variação nos dados.

2. **Análise de Clusters**: Para identificar possíveis subtipos de pacientes com perfis de risco similares, o que poderia ter implicações para estratégias de prevenção personalizadas.

3. **Análise Discriminante**: Para desenvolver modelos de classificação que possam predizer o risco de diabetes com base nas variáveis clínicas.

4. **Modelos preditivos**: Desenvolver e validar modelos de regressão logística ou algoritmos de machine learning para prever o diagnóstico de diabetes.

Estas análises poderiam contribuir para o desenvolvimento de ferramentas de rastreio mais eficazes e intervenções personalizadas para prevenção do diabetes em populações de alto risco.